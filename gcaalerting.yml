global:
  smtp_from: noreply@grafana.net
  smtp_smarthost: smtprelay:2525
  smtp_require_tls: false
receivers:
  - name: email
    email_configs:
      - send_resolved: true
        to: 
  - name: prometheus-msteams
    webhook_configs:
      - url: 

route:
  receiver: email
  group_wait: 1m
  group_interval: 1m
  repeat_interval: 3h
templates: []



---
alert: Agent_Down
expr: max_over_time(up{job="integrations/agent"}[1h]) unless up
annotations:
  description: Agent $hostname is down
  summary: Please check agent $hostname is not responding
---

global:
  resolve_timeout: 5m
  smtp_from: noreply@grafana.net
  smtp_smarthost: smtprelay:2525
  smtp_require_tls: false
route:
  group_by:
    - instance
    - alert
  receiver: prometheus-msteams
  group_wait: 1m
  group_interval: 1m
  repeat_interval: 2m
receivers:
  - name: prometheus-msteams
    webhook_configs:
      - url: 
        send_resolved: true
templates: []

---

route:
  group_by: ['alertname']
  group_interval: 30s
  repeat_interval: 30s
  group_wait: 30s
  receiver: 'prometheus-msteams'

receivers:
- name: 'prometheus-msteams'
  webhook_configs: 
  - send_resolved: true
    url: 


server:
  log_level: info
  http_listen_port: 12345
prometheus:
  wal_directory: /opt/GCA/wal
  global:

    scrape_interval: 15s
  configs:
    - name: test
      host_filter: false
      scrape_configs:
        - job_name: 'postgres_exporter'
          static_configs:
            - targets: ['127.0.0.1:9187']
      remote_write:
      - url: https://prometheus-us-central1.grafana.net/api/prom/push
        basic_auth:
          username: 17048
          password: eyJrIjoiZmJjM2FhN2JhN2MxNDA2NjZlMGY0ZDBmY2I1NDM3YWI2MmZhNWRmZiIsIm4iOiJwb2NtYWxhdXphaS1wcm9tIiwiaWQiOjQyNjc5OH0=

    - name: process
      host_filter: false
      scrape_configs:
        - job_name: 'process_exporter'
          static_configs:
            - targets: ['127.0.0.1:9256']

    - job_name: 'blackbox_icmp'
         metrics_path: /probe
         params:
           module: [icmp]
         azure_sd_configs:
           - environment: AzurePublicCloud
             authentication_method: OAuth
             subscription_id: 
             tenant_id: 
             client_id: 
             secret_id: 
             port: 9115

         relabel_configs:
         - source_labels: [__meta_azure_machine_tag_Dev/Test]
           regex: true.*
           action: keep
         - source_labels: [__meta_azure_machine_name]
           target_label: instance
         - target_label: _address_
           replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.

   
    - job_name: 'blackbox_icmp'
         metrics_path: /probe
         params:
           module: [icmp]
         file_sd_config:
         - files:
           - 'targets.json'

         relabel_configs:
         - source_labels: [__address__]
           target_label: __param_target
         - source_labels: [__address__]
           target_label: instance
         - target_label: __address__
           replacement: 127.0.0.1:9115 

      remote_write:
      - url: 
        basic_auth:
          username: 
          password: 

loki_config:
  configs:
  - name: default
    positions:
      filename: /opt/postgres/positions.yaml
    clients:
      - url: 
    scrape_configs:
    - job_name: postgres
      static_configs:
        - targets:
          - localhost
          labels:
            job: pglogs
            __path__: /pgsql_data/9.6/data/pg_log/*.log

integrations:
  agent:
    enabled: true
  node_exporter:
    enabled: true

    diskstats_ignored_devices: <string> | false = "^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\\d+n\\d+p)\\d+$"
    filesystem_ignored_mount_points: <string> | false = "^/(dev|var/lib/docker/.+)($|/)"
    filesystem_ignored_fs_types: <string> | false = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
  prometheus_remote_write:
   - url: https://prometheus-us-central1.grafana.net/api/prom/push
     basic_auth:
       username: 23260
       password: eyJrIjoiZTI5OTdmZDZhOTliYjA2YzExMjljMzgxODg2M2FhZWNiMjAyNDNlYyIsIm4iOiJtYWxhdXphaXZtcG9jIiwiaWQiOjQyNjc5OH0=
                                                                                                                              


 - name: Redis
     host_filter: false
     scrape_configs:
       - job_name: 'redis_prometheus_exporter'
         static_configs:
           - targets: ['1:9121']                                                            
           
---
global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.org'
  smtp_auth_username: 'alertmanager'
  smtp_auth_password: 'password'

# The directory from which notification templates are read.
templates:
- '/etc/alertmanager/template/*.tmpl'

# The root route on which each incoming alert enters.
route:
  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use '...' as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: ['alertname', 'cluster', 'service']

  # When a new group of alerts is created by an incoming alert, wait at
  # least 'group_wait' to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait 'group_interval' to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait 'repeat_interval' to
  # resend them.
  repeat_interval: 3h

  # A default receiver
  receiver: team-X-mails

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This routes performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~"foo1|foo2|baz"
    receiver: team-X-mails
    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to 'team-X-mails'
    routes:
    - matchers:
      - severity="critical"
      receiver: team-X-pager
  - matchers:
    - service="files"
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity="critical"
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there's
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service="database"
    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]
    routes:
    - matchers:
      - owner="team-X"
      receiver: team-X-pager
      continue: true
    - matchers:
      - owner="team-Y"
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers: [ severity="critical" ]
  target_matchers: [ severity="warning" ]
  # Apply inhibition if the alertname is the same.
  # CAUTION:
  #   If all label names listed in `equal` are missing
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: [ alertname, cluster, service ]


receivers:
- name: 'team-X-mails'
  email_configs:
  - to: 'team-X+alerts@example.org'

- name: 'team-X-pager'
  email_configs:
  - to: 'team-X+alerts-critical@example.org'
  pagerduty_configs:
  - service_key: <team-X-key>

- name: 'team-Y-mails'
  email_configs:
  - to: 'team-Y+alerts@example.org'

- name: 'team-Y-pager'
  pagerduty_configs:
  - service_key: <team-Y-key>

- name: 'team-DB-pager'
  pagerduty_configs:
  - service_key: <team-DB-key>


---
 global:
  resolve_timeout: 5m
  http_config:
    follow_redirects: true
  smtp_from: noreply@grafana.net
  smtp_hello: localhost
  smtp_smarthost: smtprelay:2525
  smtp_require_tls: false
  pagerduty_url: https://events.pagerduty.com/v2/enqueue
  opsgenie_api_url: https://api.opsgenie.com/
  wechat_api_url: https://qyapi.weixin.qq.com/cgi-bin/
  victorops_api_url: https://alert.victorops.com/integrations/generic/20131114/alert/
route:
  receiver: email
  continue: false
  routes:
    - matchers:
        - environment="dev"
      receiver: tedt
    - matchers:
        - environment="qa"
      receiver: malauzai_qa_email
    - matchers:
        - environment="uat"
      receiver: uat_email
receivers:
  - name: email
    email_configs:
      - send_resolved: false
        to: example@email.com
        from: noreply@grafana.net
        hello: localhost
        smarthost: smtprelay:2525
        headers:
          From: noreply@grafana.net
          Subject: '{{ template "email.default.subject" . }}'
  - name: dev_email
    email_configs:
      - send_resolved: false
        to: email.com
        from: noreply@grafana.net
        hello: localhost
        smarthost: smtprelay:2525
        headers:
          From: noreply@grafana.net
          Subject: '{{ template "email.default.subject" . }}'
  - name: qa_email
    email_configs:
      - send_resolved: false
        to: 
        from: noreply@grafana.net
        hello: localhost
        smarthost: smtprelay:2525
        headers:
          From: noreply@grafana.net
          Subject: '{{ template "email.default.subject" . }}'
  - name: malauzai_uat_email
    email_configs:
      - send_resolved: false
        to: 
        from: noreply@grafana.net
        hello: localhost
        smarthost: smtprelay:2525
        headers:
          From: noreply@grafana.net
          Subject: '{{ template "email.default.subject" . }}'
templates: []



---

server:
  log_level: info
  http_listen_port: 12345
prometheus:
  wal_directory: /opt/GCA/wal
  global:
    scrape_interval: 15s
  configs:
   - name: default
     host_filter: false
     scrape_configs:
       - job_name: 'postgres_exporter'
         static_configs:
           - targets: ['127.0.0.1:9187']
         metric_relabel_configs:
         - source_labels: [__name__]
           regex: '(pg_locks_count|pg_settings_arr)'
           action: drop
       - job_name: 'process_exporter'
         static_configs:
           - targets: ['127.0.0.1:9256']

       - job_name: 'blacbox'
         metrics_path: /probe
         params:
           module: [http_2xx]  # Look for a HTTP 200 response.
         static_configs:
           - targets:
             - https://example.com   # Target to probe with http.
             - http://example.com   # Target to probe with https.
#             - http://example.com:8080 # Target to probe with http on port 8080.
         relabel_configs:

         - source_labels: [__param_module]
           target_label: module
         - source_labels: [__address__]
           target_label: __param_target
         - source_labels: [__param_target]
           target_label: instance
         - target_label: __address__
           replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.

      
   
    remote_write:
      - url: 
        basic_auth:
          username: 
          password: 
loki:
  configs:
  - name: default
    positions:
      filename: /opt/postgres/positions.yaml
    clients:
      - url:xxx
    scrape_configs:
    - job_name: postgres
      static_configs:
        - targets:
          - localhost
          labels:
            job: pglogs
            __path__: /pgsql_data/9.6/data/pg_log/*.log

integrations:
  agent:
    enabled: true
  node_exporter:
    enabled: true

    
  prometheus_remote_write:
   - url: 
     basic_auth:
       username: 
       password: 
